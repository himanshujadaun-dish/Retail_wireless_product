# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GlLIqTgP1stjUnurjFd8hJee3EWdyNgB
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import time  # Used to simulate a 'typing' response
# 
# # ------------------------------------------------------------
# # 1. PAGE CONFIGURATION & BRANDING
# # ------------------------------------------------------------
# st.set_page_config(
#     page_title="Wireless Cortex AI",
#     page_icon="üì∂",
#     layout="wide"
# )
# 
# # --- Custom CSS ---
# st.markdown("""
# <style>
# .stApp {
#     background-color: #f0f2f6;
# }
# .stChatMessage[data-testid="stChatMessage"]:nth-child(even) {
#     background-color: #e6f7ff;
#     border-radius: 15px;
# }
# .stChatMessage[data-testid="stChatMessage"]:nth-child(odd) {
#     background-color: #ffffff;
#     border-radius: 15px;
# }
# </style>
# """, unsafe_allow_html=True)
# 
# 
# # ------------------------------------------------------------
# # 2. SIDEBAR - CONTEXT AND CONTROLS
# # ------------------------------------------------------------
# with st.sidebar:
#     st.title("‚öôÔ∏è Assistant Context & Tools")
#     st.header("üë§ User Account (Simulated)")
#     st.markdown("### **Account: 9001-A-42**")
#     st.metric("Current Plan", "Unlimited 5G Pro")
#     st.metric("Bill Due Date", "Dec 1, 2025")
#     st.info("üí° Bot uses this info to personalize answers.")
# 
#     st.markdown("---")
#     if st.button("üóëÔ∏è Start New Conversation", use_container_width=True):
#         st.session_state.messages = []
#         st.rerun()
#     st.markdown("---")
# 
#     st.header("ü§ñ Cortex Settings")
#     selected_model = st.selectbox(
#         "Select LLM Backend",
#         ["Cortex-Optimized-7B (Default)", "GPT-4 Turbo", "Custom RAG Model"]
#     )
#     temperature = st.slider("Response Focus (Temperature)", 0.0, 1.0, 0.2)
# 
# 
# # ------------------------------------------------------------
# # 3. MAIN INTERFACE - CHAT WINDOW
# # ------------------------------------------------------------
# st.title("üì∂ Retail Wireless Assistant")
# 
# # Initialize chat history
# if "messages" not in st.session_state:
#     st.session_state.messages = []
#     with st.chat_message("assistant", avatar="ü§ñ"):
#         st.write("Hello! I'm your **Cortex AI Wireless Expert**.")
#         st.write("How can I help you today?")
#         st.markdown("""
#         * **Plan Upgrades & Pricing**
#         * **Latest Device Specs**
#         * **Billing & Account Questions**
#         * **Technical Troubleshooting**
#         """)
# 
# # Display existing chat history
# for message in st.session_state.messages:
#     with st.chat_message(message["role"], avatar=message["avatar"]):
#         st.markdown(message["content"])
# 
# # --- Main Input Logic ---
# if prompt := st.chat_input("Ask about plans, devices, or your account..."):
#     st.session_state.messages.append({"role": "user", "avatar": "üë§", "content": prompt})
#     with st.chat_message("user", avatar="üë§"):
#         st.markdown(prompt)
# 
#     with st.chat_message("assistant", avatar="ü§ñ"):
#         with st.spinner(f"Cortex AI is consulting the {selected_model} model..."):
#             time.sleep(1)
# 
#         response = (
#             f"That‚Äôs a great question about the **iPhone 16 Pro Max**! "
#             f"Based on your **{st.session_state.get('plan', 'Unlimited 5G Pro')}** plan, "
#             f"you‚Äôre eligible for an upgrade **with no upfront cost**. "
#             f"The device features a 120 Hz ProMotion display and a 5√ó Telephoto camera."
#         )
# 
#         # Simulate typing animation
#         full_response, placeholder = "", st.empty()
#         for word in response.split():
#             full_response += word + " "
#             placeholder.markdown(full_response + "‚ñå")
#             time.sleep(0.04)
#         placeholder.markdown(full_response)
# 
#         st.session_state.messages.append({"role": "assistant", "avatar": "ü§ñ", "content": full_response})
# 
#         st.markdown("---")
#         st.subheader("Next Steps")
#         c1, c2, c3 = st.columns(3);
#         with c1: st.button("üí∞ Get Quote", key="quote")
#         with c2: st.button("üîó View Specs", key="specs")
#         with c3: st.button("‚öôÔ∏è Start Upgrade", key="upgrade")
# 
#         with st.expander("üìö Sources & References"):
#             st.markdown("""
#             * **Product Catalog:** iPhone 16 Pro Max Q4-2025 .pdf
#             * **Policy:** Upgrade Eligibility Matrix v1.2
#             """)

# ============================================================
#  STEP 1Ô∏è‚É£  ‚Äî  Install Dependencies
# ============================================================
pip install streamlit pyngrok --quiet

# ============================================================
#  STEP 3Ô∏è‚É£  ‚Äî  Launch Streamlit in Colab
# ============================================================
from pyngrok import ngrok

# IMPORTANT: Replace 'YOUR_NGROK_AUTHTOKEN' with your actual ngrok authtoken.
# You can get one from your ngrok dashboard: https://dashboard.ngrok.com/get-started/your-authtoken
# You can also set it once for your system using: ngrok config add-authtoken <YOUR_AUTHTOKEN>
# For this Colab, we'll set it directly in the code for demonstration.
ngrok.set_auth_token("357VmRuIPdSFgyB35qwNU1u8TUc_4x3oRAxcDHeWFhVrWAvzc")

public_url = ngrok.connect(8501)
print("Public URL ‚Üí", public_url)

streamlit run app.py &>/dev/null & sleep 5
print("‚úÖ Streamlit server started!  Click the public URL above to view your app.")
